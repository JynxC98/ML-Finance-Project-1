{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Group project - A neural Network model to compute implied volatility from option prices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import qmc\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import R2Score\n",
    "from IPython.display import display, Markdown"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first create a sample dataset of model parameters by using moneynees S/K instead of\n",
    "S and K separately. Thus, we create input features as\n",
    "1. Moneyness: S/K with a narrow range: [0.5, 1.5] and a wide range: [0.4, 1.6]\n",
    "2. Time to maturity: τ with a narrow range: [0.3, 0.95] and a wide range: [0.2, 1.1]\n",
    "3. Risk free rate: r with a narrow range: [0.03, 0.08] and a wide range: [0.02, 0.1]\n",
    "4. Volatility: σ with a narrow range: [0.02, 0.9] and a wide range: [0.01, 1.0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def black_scholes_price(data):\n",
    "    d1 = (np.log(data[:,0]) + (data[:,2] + (0.5*data[:,3]**2))*data[:,1]\n",
    "          )/(data[:,3]*np.sqrt(data[:,1]))\n",
    "    d2 = (np.log(data[:,0]) + (data[:,2] - (0.5*data[:,3]**2))*data[:,1]\n",
    "          )/(data[:,3]*np.sqrt(data[:,1]))\n",
    "    return data[:,0]*norm.cdf(d1) - np.exp(-1*data[:,1]*data[:,2]) \\\n",
    "        *norm.cdf(d2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "lhs = qmc.LatinHypercube(d=4, seed=1)\n",
    "sample = lhs.random(n=1000000)\n",
    "n_l_bounds = [0.5, 0.3, 0.03, 0.02]\n",
    "n_u_bounds = [1.5, 0.95, 0.08, 0.9]\n",
    "w_l_bounds = [0.4, 0.2, 0.02, 0.01]\n",
    "w_u_bounds = [1.6, 1.1, 0.1, 1.0]\n",
    "narrow_data  = qmc.scale(sample, n_l_bounds, n_u_bounds)\n",
    "narrow_data = np.column_stack((black_scholes_price(narrow_data),\n",
    "                               narrow_data))\n",
    "wide_data  = qmc.scale(sample, w_l_bounds, w_u_bounds)\n",
    "wide_data = np.column_stack((black_scholes_price(wide_data),\n",
    "                             wide_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing step"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "narrow_data[:,0] = narrow_data[:,0] - np.maximum(narrow_data[:,1] - np.exp(-1*narrow_data[:,3] * narrow_data[:,2]), 0)\n",
    "narrow_data = narrow_data[narrow_data[:,0] >= 10e-7]\n",
    "narrow_data[:, 0] = np.log(narrow_data[:, 0])\n",
    "wide_data[:,0] = wide_data[:,0] - np.maximum(wide_data[:,1] - np.exp(-1*wide_data[:,3] * wide_data[:,2]), 0)\n",
    "wide_data = wide_data[wide_data[:,0] >= 10e-7]\n",
    "wide_data[:, 0] = np.log(wide_data[:, 0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Divide the data into training, validation and test sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "def split_data(data, scale):\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        data[:, [0,1,2,3]], narrow_data[:,4], test_size=0.2,\n",
    "        random_state=1)\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=1)\n",
    "\n",
    "    X_train = torch.from_numpy(X_train).float().to('cuda')\n",
    "    y_train = torch.from_numpy(y_train).float().to('cuda')\n",
    "    X_valid = torch.from_numpy(X_valid).float().to('cuda')\n",
    "    y_valid = torch.from_numpy(y_valid).float().to('cuda')\n",
    "    X_test = torch.from_numpy(X_test).float().to('cuda')\n",
    "    y_test = torch.from_numpy(y_test).float().to('cuda')\n",
    "    del X_temp, y_temp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
